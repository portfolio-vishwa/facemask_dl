{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face mask detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pathlib\n",
    "import re\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../dataset\"\n",
    "batch_size = 32\n",
    "\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "IMG_SIZE = 150\n",
    "\n",
    "class_names = ['with_mask', 'without_mask']\n",
    "class_names_label = {class_name:i for i, class_name in enumerate(class_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(path):\n",
    "    \"\"\"\n",
    "    Read images from the path & preprocess it\n",
    "    \n",
    "    Args:\n",
    "        path(String/pathlib) - path of the image files\n",
    "    \n",
    "    Returns:\n",
    "        x - processed X data\n",
    "        y - corresponding y labels of x\n",
    "    \"\"\"\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    path = pathlib.Path(path)\n",
    "    \n",
    "    sub_folders = [x for x in data_dir.iterdir()] \n",
    "    \n",
    "    for folder in sub_folders:\n",
    "        images_path= folder.glob('**/*.jpg')\n",
    "        \n",
    "        for img_path in images_path :\n",
    "            img=load_img(img_path, target_size=(IMG_SIZE,IMG_SIZE))\n",
    "            img=img_to_array(img)\n",
    "            img=img/255.0\n",
    "            x.append(img)\n",
    "            y.append(class_names_label[folder.name])\n",
    "    \n",
    "    return np.array(x),np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = prepare_dataset(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(x,y,test_ratio = 0.2):\n",
    "    \"\"\"\n",
    "    Split the given data into test and train set\n",
    "    \n",
    "    Args:\n",
    "        x(numpy array): x data with first dimension as the samples\n",
    "        y(numpy array): corresponding labels to x \n",
    "        test_ratio(0-1): ratio of data required for test set\n",
    "        \n",
    "    Returns:\n",
    "        x_train(numpy_array) - training x data\n",
    "        y_train(numpy_array) - training y data\n",
    "        x_test(numpy_array) - test x data\n",
    "        y_test(numpy_array) - test y data\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(x,\n",
    "                                                    y,\n",
    "                                                    test_size=test_ratio,\n",
    "                                                    random_state=42)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = split_train_test(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the shape of the content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in training:1100\n",
      "Number of samples in test:150\n",
      "Dimension of each sample: (150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples in training:\" + str(x_train.shape[0]))\n",
    "print(\"Number of samples in test:\" + str(x_train.shape[1]))\n",
    "\n",
    "print(\"Dimension of each sample: \" + str(x_train.shape[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todo\n",
    "\n",
    "* Display some random images\n",
    "* Split the data to train and test set - done\n",
    "* Display the class level split in both test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (IMG_SIZE, IMG_SIZE, 3)), \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 72, 72, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 41472)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               5308544   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 5,318,817\n",
      "Trainable params: 5,318,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/35 [==============================] - 11s 310ms/step - loss: 0.6183 - acc: 0.6600 - val_loss: 0.4551 - val_acc: 0.7754\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 10s 298ms/step - loss: 0.3530 - acc: 0.8782 - val_loss: 0.3800 - val_acc: 0.8442\n",
      "Epoch 3/100\n",
      "30/35 [========================>.....] - ETA: 1s - loss: 0.2577 - acc: 0.9135"
     ]
    }
   ],
   "source": [
    "history=model.fit(x=x_train,y=y_train,epochs=100,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
